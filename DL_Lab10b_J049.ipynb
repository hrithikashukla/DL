{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expt 10b - Keras_bottleneck_features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkuVZh7bLqx",
        "colab_type": "text"
      },
      "source": [
        "#Transfer Learning\n",
        "\n",
        "In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest. The three major Transfer Learning scenarios look as follows:\n",
        "\n",
        "ConvNet as fixed feature extractor. Take a ConvNet pretrained on ImageNet, remove the last fully-connected layer (this layer’s outputs are the 1000 class scores for a different task like ImageNet), then treat the rest of the ConvNet as a fixed feature extractor for the new dataset. In an AlexNet, this would compute a 4096-D vector for every image that contains the activations of the hidden layer immediately before the classifier. We call these features CNN codes. It is important for performance that these codes are ReLUd (i.e. thresholded at zero) if they were also thresholded during the training of the ConvNet on ImageNet (as is usually the case). Once you extract the 4096-D codes for all images, train a linear classifier (e.g. Linear SVM or Softmax classifier) for the new dataset.\n",
        "\n",
        "#Fine-tuning the ConvNet. \n",
        "\n",
        "The second strategy is to not only replace and retrain the classifier on top of the ConvNet on the new dataset, but to also fine-tune the weights of the pretrained network by continuing the backpropagation. It is possible to fine-tune all the layers of the ConvNet, or it’s possible to keep some of the earlier layers fixed (due to overfitting concerns) and only fine-tune some higher-level portion of the network. This is motivated by the observation that the earlier features of a ConvNet contain more generic features (e.g. edge detectors or color blob detectors) that should be useful to many tasks, but later layers of the ConvNet becomes progressively more specific to the details of the classes contained in the original dataset. In case of ImageNet for example, which contains many dog breeds, a significant portion of the representational power of the ConvNet may be devoted to features that are specific to differentiating between dog breeds.\n",
        "\n",
        "#Pretrained models. \n",
        "\n",
        "Since modern ConvNets take 2-3 weeks to train across multiple GPUs on ImageNet, it is common to see people release their final ConvNet checkpoints for the benefit of others who can use the networks for fine-tuning. For example, the Caffe library has a Model Zoo where people share their network weights.\n",
        "When and how to fine-tune? How do you decide what type of transfer learning you should perform on a new dataset? This is a function of several factors, but the two most important ones are the size of the new dataset (small or big), and its similarity to the original dataset (e.g. ImageNet-like in terms of the content of images and the classes, or very different, such as microscope images). Keeping in mind that ConvNet features are more generic in early layers and more original-dataset-specific in later layers, here are some common rules of thumb for navigating the 4 major scenarios:\n",
        "\n",
        "New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
        "New dataset is large and similar to the original dataset. Since we have more data, we can have more confidence that we won’t overfit if we were to try to fine-tune through the full network.\n",
        "New dataset is small but very different from the original dataset. Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier form the top of the network, which contains more dataset-specific features. Instead, it might work better to train the SVM classifier from activations somewhere earlier in the network.\n",
        "New dataset is large and very different from the original dataset. Since the dataset is very large, we may expect that we can afford to train a ConvNet from scratch. However, in practice it is very often still beneficial to initialize with weights from a pretrained model. In this case, we would have enough data and confidence to fine-tune through the entire network.\n",
        "Practical advice. There are a few additional things to keep in mind when performing Transfer Learning:\n",
        "\n",
        "Constraints from pretrained models. Note that if you wish to use a pretrained network, you may be slightly constrained in terms of the architecture you can use for your new dataset. For example, you can’t arbitrarily take out Conv layers from the pretrained network. However, some changes are straight-forward: Due to parameter sharing, you can easily run a pretrained network on images of different spatial size. This is clearly evident in the case of Conv/Pool layers because their forward function is independent of the input volume spatial size (as long as the strides “fit”). In case of FC layers, this still holds true because FC layers can be converted to a Convolutional Layer: For example, in an AlexNet, the final pooling volume before the first FC layer is of size [6x6x512]. Therefore, the FC layer looking at this volume is equivalent to having a Convolutional Layer that has receptive field size 6x6, and is applied with padding of 0.\n",
        "\n",
        "Learning rates. It’s common to use a smaller learning rate for ConvNet weights that are being fine-tuned, in comparison to the (randomly-initialized) weights for the new linear classifier that computes the class scores of your new dataset. This is because we expect that the ConvNet weights are relatively good, so we don’t wish to distort them too quickly and too much (especially while the new Linear Classifier above them is being trained from random initialization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpkygp28beEr",
        "colab_type": "text"
      },
      "source": [
        "#ImageNet \n",
        "\n",
        "The id’s of the 2 object classes we are considering are given below\n",
        "\n",
        "```\n",
        "Ships and bikes\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy-kc6xzaNdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\")#ship synset\n",
        "print(page.content)\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "soup = BeautifulSoup(page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")#bicycle synset\n",
        "print(bikes_page.content)\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "from bs4 import BeautifulSoup\n",
        "bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "str_soup=str(soup)#convert soup to string so it can be split\n",
        "type(str_soup)\n",
        "split_urls=str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(split_urls))#print the length of the list so you know how many urls you have\n",
        "\n",
        "bikes_str_soup=str(bikes_soup)#convert soup to string so it can be split\n",
        "type(bikes_str_soup)\n",
        "bikes_split_urls=bikes_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(bikes_split_urls))\n",
        "\n",
        "!mkdir /content/train #create the Train folder\n",
        "!mkdir /content/train/ships #create the ships folder\n",
        "!mkdir /content/train/bikes #create the bikes folder\n",
        "!mkdir /content/validation\n",
        "!mkdir /content/validation/ships #create the ships folder\n",
        "!mkdir /content/validation/bikes #create the bikes folder\n",
        "\n",
        "#code part 4\n",
        "img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n",
        "\n",
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=100#the number of training images to use\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "        \n",
        "#Validation data:\n",
        "\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "print(\"\\nTRAIN:\\n\")          \n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/train/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/train/bikes #list the files inside bikes\n",
        "print(\"\\nVALIDATION:\\n\")\n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/validation/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/validation/bikes #list the files inside bikes   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YdqAb33hSeI",
        "colab_type": "text"
      },
      "source": [
        "#Data pre-processing and data augmentation\n",
        "\n",
        "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n",
        "\n",
        "In Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class. This class allows you to:\n",
        "\n",
        "1. configure random transformations and normalization operations to be done on your image data during training\n",
        "2. instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPjFTAkcfhxl",
        "colab_type": "text"
      },
      "source": [
        "#Load the pre-trained model VGG16\n",
        "\n",
        "Our strategy will be as follow: we will only instantiate the convolutional part of the model, everything up to the fully-connected layers. We will then run this model on our training and validation data once, recording the output (the \"bottleneck features\" from th VGG16 model: the last activation maps before the fully-connected layers) in two numpy arrays. Then we will train a small fully-connected model on top of the stored features.\n",
        "\n",
        "![alt text](http://upscfever.com/upsc-fever/en/data/images/vgg16_original.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81yFCOcjhc-T",
        "colab_type": "code",
        "outputId": "3602a317-5274-40cf-f3b5-85d965afd656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'vgg16_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('vgg16_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('vgg16_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('vgg16_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('vgg16_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 2.0958 - accuracy: 0.5833 - val_loss: 1.1852 - val_accuracy: 0.4667\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 930us/step - loss: 1.2055 - accuracy: 0.5833 - val_loss: 1.0890 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9813 - accuracy: 0.7333 - val_loss: 2.3753 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 939us/step - loss: 0.7364 - accuracy: 0.7333 - val_loss: 1.3707 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 945us/step - loss: 0.3679 - accuracy: 0.8167 - val_loss: 1.4402 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 973us/step - loss: 0.3304 - accuracy: 0.8667 - val_loss: 1.2729 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 967us/step - loss: 0.3469 - accuracy: 0.8333 - val_loss: 1.8804 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9500 - val_loss: 1.9727 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 959us/step - loss: 0.1575 - accuracy: 0.9333 - val_loss: 1.9006 - val_accuracy: 0.4667\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 993us/step - loss: 0.2668 - accuracy: 0.8333 - val_loss: 1.8530 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 976us/step - loss: 0.2872 - accuracy: 0.9333 - val_loss: 2.1664 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 984us/step - loss: 0.0300 - accuracy: 0.9833 - val_loss: 2.2950 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 2.1150 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 953us/step - loss: 0.0681 - accuracy: 0.9667 - val_loss: 2.2732 - val_accuracy: 0.5333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 988us/step - loss: 0.0744 - accuracy: 0.9667 - val_loss: 2.2646 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.4430 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 954us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4240 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 6.8043e-04 - accuracy: 1.0000 - val_loss: 2.5677 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.4538 - val_accuracy: 0.4333\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9667 - val_loss: 4.0811 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6352 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 8.2903e-04 - accuracy: 1.0000 - val_loss: 2.6420 - val_accuracy: 0.5333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.5050e-04 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7990e-04 - accuracy: 1.0000 - val_loss: 2.9791 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 7.3965e-05 - accuracy: 1.0000 - val_loss: 3.3717 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 4.6401e-05 - accuracy: 1.0000 - val_loss: 3.2936 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 990us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.3133 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9833 - val_loss: 5.8965 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 945us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.3399 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 934us/step - loss: 1.5556e-04 - accuracy: 1.0000 - val_loss: 3.3196 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 945us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7416 - val_accuracy: 0.5333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 980us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.2238 - val_accuracy: 0.4333\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 982us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.2001 - val_accuracy: 0.4333\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1594 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 998us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.5169 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 959us/step - loss: 6.4189e-05 - accuracy: 1.0000 - val_loss: 3.6762 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 965us/step - loss: 9.3343e-06 - accuracy: 1.0000 - val_loss: 3.6718 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 951us/step - loss: 1.7509e-05 - accuracy: 1.0000 - val_loss: 3.8794 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 947us/step - loss: 1.0342e-04 - accuracy: 1.0000 - val_loss: 3.8221 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 949us/step - loss: 2.8033e-06 - accuracy: 1.0000 - val_loss: 3.8097 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 989us/step - loss: 1.0901e-05 - accuracy: 1.0000 - val_loss: 4.1028 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 954us/step - loss: 7.8396e-04 - accuracy: 1.0000 - val_loss: 3.8315 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 966us/step - loss: 7.6255e-04 - accuracy: 1.0000 - val_loss: 3.8955 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.9990 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 955us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.7087 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 980us/step - loss: 5.7228e-04 - accuracy: 1.0000 - val_loss: 4.8493 - val_accuracy: 0.4333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 941us/step - loss: 4.5568e-05 - accuracy: 1.0000 - val_loss: 4.4286 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 953us/step - loss: 0.0220 - accuracy: 0.9833 - val_loss: 4.6881 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 999us/step - loss: 2.4953e-05 - accuracy: 1.0000 - val_loss: 4.5443 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 995us/step - loss: 3.3705e-06 - accuracy: 1.0000 - val_loss: 4.7913 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLx8CPcgzwGC",
        "colab_type": "text"
      },
      "source": [
        "#Load the pre-trained model ResNet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkkIfOic0L2S",
        "colab_type": "code",
        "outputId": "078ad01f-c91b-4e41-fd1f-6a4d11fe0c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'resnet50_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.resnet50.ResNet50(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('resnet50_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('resnet50_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('resnet50_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('resnet50_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 5.7385 - accuracy: 0.4000 - val_loss: 3.2502 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.1570 - accuracy: 0.4667 - val_loss: 1.1146 - val_accuracy: 0.5333\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1654 - accuracy: 0.5833 - val_loss: 1.4135 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3191 - accuracy: 0.6000 - val_loss: 1.1553 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0992 - accuracy: 0.6333 - val_loss: 1.1308 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.6000 - val_loss: 0.7877 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.9550 - accuracy: 0.4500 - val_loss: 0.7405 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7766 - accuracy: 0.5333 - val_loss: 0.7571 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.6167 - val_loss: 0.7092 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6667 - val_loss: 0.7455 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.6000 - val_loss: 0.8666 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.6333 - val_loss: 0.7364 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7189 - accuracy: 0.4333 - val_loss: 0.7125 - val_accuracy: 0.3000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.5833 - val_loss: 0.7105 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.5167 - val_loss: 0.7120 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.5500 - val_loss: 0.8332 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.5667 - val_loss: 0.8036 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.5833 - val_loss: 0.7542 - val_accuracy: 0.3667\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.5667 - val_loss: 0.7248 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6000 - val_loss: 0.7267 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7167 - val_loss: 0.7642 - val_accuracy: 0.3000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6500 - val_loss: 0.7306 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.5333 - val_loss: 0.7019 - val_accuracy: 0.3667\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6333 - val_loss: 0.7374 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5667 - val_loss: 0.7923 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.5833 - val_loss: 0.7452 - val_accuracy: 0.3000\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.5333 - val_loss: 0.7989 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6333 - val_loss: 0.8063 - val_accuracy: 0.5333\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6167 - val_loss: 0.8541 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6167 - val_loss: 0.8362 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6500 - val_loss: 0.7468 - val_accuracy: 0.4333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.5833 - val_loss: 0.8743 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.5833 - val_loss: 0.8815 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.6667 - val_loss: 0.9067 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7500 - val_loss: 0.8322 - val_accuracy: 0.3667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6667 - val_loss: 0.7656 - val_accuracy: 0.3000\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.6167 - val_loss: 0.9756 - val_accuracy: 0.3667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6667 - val_loss: 0.8997 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.6500 - val_loss: 0.8481 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7167 - val_loss: 0.9709 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.6500 - val_loss: 0.9132 - val_accuracy: 0.3667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7167 - val_loss: 0.9337 - val_accuracy: 0.4333\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7833 - val_loss: 0.9234 - val_accuracy: 0.4333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7500 - val_loss: 0.9748 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7000 - val_loss: 0.8639 - val_accuracy: 0.3000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.6333 - val_loss: 0.9391 - val_accuracy: 0.3667\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7167 - val_loss: 0.8024 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7000 - val_loss: 0.8136 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.6833 - val_loss: 1.1170 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6667 - val_loss: 0.8691 - val_accuracy: 0.4333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7MJP_x-6MwN",
        "colab_type": "text"
      },
      "source": [
        "#Load Xception pretrained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo24Kg2X6NE0",
        "colab_type": "code",
        "outputId": "16403448-c836-4999-86c0-81e5ecbbd01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'xcept_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.xception.Xception(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('xcept_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('xcept_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('xcept_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('xcept_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 16.8232 - accuracy: 0.4500 - val_loss: 8.4224 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.5468 - accuracy: 0.6333 - val_loss: 7.3415 - val_accuracy: 0.5333\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.8950 - accuracy: 0.7167 - val_loss: 7.5906 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8833 - val_loss: 19.8945 - val_accuracy: 0.5333\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7488 - accuracy: 0.8500 - val_loss: 9.0996 - val_accuracy: 0.5333\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6078 - accuracy: 0.9000 - val_loss: 8.8533 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5581 - accuracy: 0.8833 - val_loss: 10.7797 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1379 - accuracy: 0.8500 - val_loss: 17.0380 - val_accuracy: 0.5667\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.3490 - accuracy: 0.8000 - val_loss: 23.4705 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.9699 - accuracy: 0.9500 - val_loss: 11.5761 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.9500 - val_loss: 10.7727 - val_accuracy: 0.5333\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8199 - accuracy: 0.9000 - val_loss: 13.6309 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 15.5389 - val_accuracy: 0.5667\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9833 - val_loss: 18.0641 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.4187 - accuracy: 0.9333 - val_loss: 11.0505 - val_accuracy: 0.5667\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.9167 - val_loss: 18.8489 - val_accuracy: 0.5667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8745 - accuracy: 0.9500 - val_loss: 11.0839 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 13.1003 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.0803e-04 - accuracy: 1.0000 - val_loss: 12.2862 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9833 - val_loss: 10.6810 - val_accuracy: 0.4333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9833 - val_loss: 21.2208 - val_accuracy: 0.5667\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9500 - val_loss: 12.1477 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.9852 - accuracy: 0.9333 - val_loss: 19.4294 - val_accuracy: 0.4333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5076e-04 - accuracy: 1.0000 - val_loss: 20.9040 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 17.0690 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9833 - val_loss: 24.4463 - val_accuracy: 0.4333\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.9833 - val_loss: 19.4033 - val_accuracy: 0.4333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6396e-07 - accuracy: 1.0000 - val_loss: 19.3322 - val_accuracy: 0.4333\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9500 - val_loss: 25.2964 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9667 - val_loss: 22.0334 - val_accuracy: 0.4333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.9500 - val_loss: 19.7616 - val_accuracy: 0.4333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.7311e-05 - accuracy: 1.0000 - val_loss: 20.3371 - val_accuracy: 0.4333\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.9500 - val_loss: 21.3978 - val_accuracy: 0.5667\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9833 - val_loss: 18.2360 - val_accuracy: 0.4333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9833 - val_loss: 24.6811 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.5922e-06 - accuracy: 1.0000 - val_loss: 23.0919 - val_accuracy: 0.4333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.9833 - val_loss: 33.1761 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.9833 - val_loss: 20.9642 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9380e-04 - accuracy: 1.0000 - val_loss: 19.6956 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2646e-09 - accuracy: 1.0000 - val_loss: 19.6910 - val_accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2495e-05 - accuracy: 1.0000 - val_loss: 17.3883 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.9833 - val_loss: 25.8829 - val_accuracy: 0.5667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9833 - val_loss: 17.2232 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9833 - val_loss: 25.1980 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.9667 - val_loss: 22.8172 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9895e-05 - accuracy: 1.0000 - val_loss: 22.2075 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0196e-08 - accuracy: 1.0000 - val_loss: 22.1800 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.4984e-14 - accuracy: 1.0000 - val_loss: 22.1800 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9833 - val_loss: 19.1724 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 18.7383 - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmQ5CGRu6p8K",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained VGG19 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lir1Z2UX6we7",
        "colab_type": "code",
        "outputId": "f560b742-9252-44a0-98e3-8b9a12478dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'vgg19_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('vgg19_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('vgg19_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('vgg19_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('vgg19_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 2s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2587 - accuracy: 0.4833 - val_loss: 1.2777 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 969us/step - loss: 0.9792 - accuracy: 0.6667 - val_loss: 2.8381 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 979us/step - loss: 0.8907 - accuracy: 0.6333 - val_loss: 1.3360 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 958us/step - loss: 0.9687 - accuracy: 0.6500 - val_loss: 1.1575 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 970us/step - loss: 0.1932 - accuracy: 0.9000 - val_loss: 1.1680 - val_accuracy: 0.4667\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 985us/step - loss: 0.3249 - accuracy: 0.8667 - val_loss: 1.3735 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7833 - val_loss: 1.2269 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9500 - val_loss: 1.2343 - val_accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 946us/step - loss: 0.0744 - accuracy: 0.9833 - val_loss: 1.2144 - val_accuracy: 0.4667\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 976us/step - loss: 0.4623 - accuracy: 0.7833 - val_loss: 1.2336 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 948us/step - loss: 0.0991 - accuracy: 0.9500 - val_loss: 1.4582 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 994us/step - loss: 0.1523 - accuracy: 0.9333 - val_loss: 1.5081 - val_accuracy: 0.3667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 939us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.4333\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 944us/step - loss: 0.0408 - accuracy: 0.9833 - val_loss: 1.6129 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 953us/step - loss: 0.0768 - accuracy: 0.9500 - val_loss: 2.2579 - val_accuracy: 0.5333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 2.0759 - val_accuracy: 0.5667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.0504 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 946us/step - loss: 0.0218 - accuracy: 0.9833 - val_loss: 2.5444 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 954us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.9630 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 994us/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 1.9478 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 924us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.2398 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 977us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.2226 - val_accuracy: 0.4667\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 972us/step - loss: 0.1611 - accuracy: 0.9167 - val_loss: 2.2904 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.2959 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 950us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4047 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 977us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3902 - val_accuracy: 0.4333\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 7.9428e-04 - accuracy: 1.0000 - val_loss: 2.5296 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9667 - val_loss: 2.2248 - val_accuracy: 0.4333\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 958us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.4503 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 983us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5067 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 988us/step - loss: 7.2333e-04 - accuracy: 1.0000 - val_loss: 3.0009 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 956us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.5842 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 984us/step - loss: 7.7792e-05 - accuracy: 1.0000 - val_loss: 2.6235 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 970us/step - loss: 1.4661e-04 - accuracy: 1.0000 - val_loss: 2.7735 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 960us/step - loss: 3.7602e-04 - accuracy: 1.0000 - val_loss: 2.8018 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 6.0360e-05 - accuracy: 1.0000 - val_loss: 3.0986 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0011 - val_accuracy: 0.4333\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0975e-04 - accuracy: 1.0000 - val_loss: 3.4667 - val_accuracy: 0.3000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 956us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.3718 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.7626e-04 - accuracy: 1.0000 - val_loss: 3.3773 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 986us/step - loss: 2.4556e-05 - accuracy: 1.0000 - val_loss: 3.4368 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 976us/step - loss: 8.6156e-06 - accuracy: 1.0000 - val_loss: 3.5088 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 966us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.1585 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.3141 - val_accuracy: 0.3667\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 970us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.2618 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 955us/step - loss: 5.6208e-04 - accuracy: 1.0000 - val_loss: 3.5076 - val_accuracy: 0.4333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 998us/step - loss: 4.4377e-05 - accuracy: 1.0000 - val_loss: 3.6637 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 942us/step - loss: 4.5637e-05 - accuracy: 1.0000 - val_loss: 3.7914 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 946us/step - loss: 1.5778e-05 - accuracy: 1.0000 - val_loss: 3.8648 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 978us/step - loss: 2.2815e-06 - accuracy: 1.0000 - val_loss: 3.8217 - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccvhU7uf7Ahz",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS9bRKXg7MQh",
        "colab_type": "code",
        "outputId": "cbd2d40d-57d3-4dc1-aa11-bfb3a68e785f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'ResNet101_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.resnet.ResNet101(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('ResNet101_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('ResNet101_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('ResNet101_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('ResNet101_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171450368/171446536 [==============================] - 4s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.1464 - accuracy: 0.5833 - val_loss: 2.1300 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.0861 - accuracy: 0.4000 - val_loss: 1.3846 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1065 - accuracy: 0.4500 - val_loss: 0.8442 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.4833 - val_loss: 1.3668 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8510 - accuracy: 0.5500 - val_loss: 0.7557 - val_accuracy: 0.3667\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7684 - accuracy: 0.6000 - val_loss: 0.7568 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.6333 - val_loss: 1.0424 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.6333 - val_loss: 0.7229 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.5000 - val_loss: 0.7150 - val_accuracy: 0.5667\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.5333 - val_loss: 0.7098 - val_accuracy: 0.4333\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.6000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7248 - accuracy: 0.5000 - val_loss: 0.6804 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5833 - val_loss: 0.7135 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.4833 - val_loss: 0.7164 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5167 - val_loss: 0.7494 - val_accuracy: 0.5333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5333 - val_loss: 0.7174 - val_accuracy: 0.5333\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6000 - val_loss: 0.7094 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6000 - val_loss: 0.7654 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6833 - val_loss: 0.8172 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7560 - accuracy: 0.5333 - val_loss: 0.7876 - val_accuracy: 0.4333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.5833 - val_loss: 0.7585 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.6667 - val_loss: 0.7345 - val_accuracy: 0.4333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.5000 - val_loss: 0.7124 - val_accuracy: 0.4333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.5833 - val_loss: 0.7221 - val_accuracy: 0.4333\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.6833 - val_loss: 0.7762 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6833 - val_loss: 0.9599 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6333 - val_loss: 0.8227 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6500 - val_loss: 0.7207 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6167 - val_loss: 0.7761 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6667 - val_loss: 0.7552 - val_accuracy: 0.4333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6500 - val_loss: 0.7238 - val_accuracy: 0.5333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6500 - val_loss: 0.7424 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6500 - val_loss: 0.7613 - val_accuracy: 0.5667\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7833 - val_loss: 0.7729 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.5333 - val_loss: 0.7824 - val_accuracy: 0.5333\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6500 - val_loss: 0.7140 - val_accuracy: 0.4333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.5500 - val_loss: 0.7966 - val_accuracy: 0.3667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.5500 - val_loss: 0.7121 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6000 - val_loss: 0.7320 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7000 - val_loss: 0.7449 - val_accuracy: 0.4333\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.6500 - val_loss: 0.8667 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6167 - val_loss: 0.7850 - val_accuracy: 0.6333\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.6667 - val_loss: 0.7747 - val_accuracy: 0.6333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6167 - val_loss: 0.7592 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7167 - val_loss: 0.7611 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.5667 - val_loss: 0.8107 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6333 - val_loss: 0.8103 - val_accuracy: 0.4333\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7000 - val_loss: 0.8024 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7167 - val_loss: 0.8443 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.6000 - val_loss: 0.7396 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtYljidy7WgZ",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained ResNet152"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4J53R3i7ajK",
        "colab_type": "code",
        "outputId": "ab949347-387a-41fa-c1f1-95d59c2b26e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'ResNet152_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.resnet.ResNet101(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('ResNet152_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('ResNet152_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('ResNet152_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('ResNet152_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 3.5222 - accuracy: 0.4833 - val_loss: 4.0025 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.7301 - accuracy: 0.5000 - val_loss: 3.0554 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.2493 - accuracy: 0.4667 - val_loss: 2.5853 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.5511 - accuracy: 0.5500 - val_loss: 1.8684 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3781 - accuracy: 0.4833 - val_loss: 0.8402 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1525 - accuracy: 0.4833 - val_loss: 0.7611 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7277 - accuracy: 0.6000 - val_loss: 1.1217 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6167 - val_loss: 0.7256 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.6500 - val_loss: 0.7624 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7949 - accuracy: 0.5833 - val_loss: 0.8816 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.5000 - val_loss: 0.7851 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.5667 - val_loss: 0.7770 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7314 - accuracy: 0.6000 - val_loss: 0.7746 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.5500 - val_loss: 0.7197 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5333 - val_loss: 0.7866 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.5667 - val_loss: 0.8152 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6333 - val_loss: 0.7752 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6000 - val_loss: 0.8985 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.6333 - val_loss: 0.7823 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.6167 - val_loss: 0.8008 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.4833 - val_loss: 0.7384 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5833 - val_loss: 0.8417 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6667 - val_loss: 0.9947 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.5667 - val_loss: 0.7646 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5667 - val_loss: 0.7504 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.5833 - val_loss: 0.7200 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7000 - val_loss: 0.7202 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.5667 - val_loss: 0.7989 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6500 - val_loss: 0.7477 - val_accuracy: 0.5667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.6833 - val_loss: 0.7804 - val_accuracy: 0.4333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.6333 - val_loss: 0.9116 - val_accuracy: 0.5333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.6333 - val_loss: 0.8533 - val_accuracy: 0.3667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.5833 - val_loss: 0.7552 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.6667 - val_loss: 0.7434 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6167 - val_loss: 0.7312 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.6667 - val_loss: 0.7247 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6167 - val_loss: 0.7788 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6000 - val_loss: 0.8059 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6167 - val_loss: 0.7492 - val_accuracy: 0.6333\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.6500 - val_loss: 0.8901 - val_accuracy: 0.5333\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.6833 - val_loss: 0.9527 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7000 - val_loss: 0.7851 - val_accuracy: 0.4333\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.6667 - val_loss: 0.7892 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6833 - val_loss: 0.8242 - val_accuracy: 0.5667\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.6500 - val_loss: 0.7774 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7000 - val_loss: 0.8204 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6000 - val_loss: 0.7653 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7167 - val_loss: 0.8722 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7000 - val_loss: 0.8922 - val_accuracy: 0.5667\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6833 - val_loss: 0.9065 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBTcXT7V7gVl",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained ResNet50V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsyYw31q8BiB",
        "colab_type": "code",
        "outputId": "23ee1085-aa6f-4f58-95a1-1aded29b05e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'ResNet50V2_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.resnet_v2.ResNet50V2(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('ResNet50V2_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('ResNet50V2_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('ResNet50V2_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('ResNet50V2_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 23.9481 - accuracy: 0.5500 - val_loss: 16.5671 - val_accuracy: 0.5333\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.2452 - accuracy: 0.8000 - val_loss: 10.8218 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4653 - accuracy: 0.8500 - val_loss: 10.7405 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7924 - accuracy: 0.8833 - val_loss: 11.1128 - val_accuracy: 0.3667\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8444 - accuracy: 0.9167 - val_loss: 12.2987 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9667 - val_loss: 14.5612 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.9833 - val_loss: 9.6960 - val_accuracy: 0.3667\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9833 - val_loss: 16.1897 - val_accuracy: 0.4333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9667 - val_loss: 15.1765 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8639 - accuracy: 0.9500 - val_loss: 22.4093 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 17.0761 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9833 - val_loss: 15.8995 - val_accuracy: 0.4333\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3169e-04 - accuracy: 1.0000 - val_loss: 16.0391 - val_accuracy: 0.4333\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0896e-09 - accuracy: 1.0000 - val_loss: 16.0391 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9833 - val_loss: 14.0909 - val_accuracy: 0.4333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.9833 - val_loss: 16.0791 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 13.7765 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9833 - val_loss: 21.1884 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9833 - val_loss: 14.0489 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.7521e-07 - accuracy: 1.0000 - val_loss: 14.1546 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.2996e-08 - accuracy: 1.0000 - val_loss: 14.1188 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9833 - val_loss: 15.6564 - val_accuracy: 0.5333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.9667 - val_loss: 15.0602 - val_accuracy: 0.4333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.5444e-07 - accuracy: 1.0000 - val_loss: 14.7190 - val_accuracy: 0.4333\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3807e-07 - accuracy: 1.0000 - val_loss: 15.4485 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2257e-04 - accuracy: 1.0000 - val_loss: 18.1443 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9833 - val_loss: 12.9432 - val_accuracy: 0.4333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9833 - val_loss: 16.5633 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.6258e-05 - accuracy: 1.0000 - val_loss: 14.8792 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.2697e-07 - accuracy: 1.0000 - val_loss: 14.6836 - val_accuracy: 0.4333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1889e-05 - accuracy: 1.0000 - val_loss: 14.5464 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.9833 - val_loss: 14.0474 - val_accuracy: 0.4333\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.7705e-10 - accuracy: 1.0000 - val_loss: 14.0474 - val_accuracy: 0.4333\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5914e-05 - accuracy: 1.0000 - val_loss: 14.1414 - val_accuracy: 0.4333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3282e-17 - accuracy: 1.0000 - val_loss: 14.1414 - val_accuracy: 0.4333\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9833 - val_loss: 21.1615 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.6445e-10 - accuracy: 1.0000 - val_loss: 21.1549 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.1442e-10 - accuracy: 1.0000 - val_loss: 21.1187 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 16.1899 - val_accuracy: 0.3667\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9833 - val_loss: 18.2636 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6466e-14 - accuracy: 1.0000 - val_loss: 18.2636 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 22.0983 - val_accuracy: 0.5333\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9833 - val_loss: 19.2433 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9667 - val_loss: 20.9203 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4646e-10 - accuracy: 1.0000 - val_loss: 20.9178 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8680e-12 - accuracy: 1.0000 - val_loss: 20.9178 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.5826e-14 - accuracy: 1.0000 - val_loss: 20.9178 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2862e-09 - accuracy: 1.0000 - val_loss: 20.9048 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.2548e-15 - accuracy: 1.0000 - val_loss: 20.9048 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.7597e-10 - accuracy: 1.0000 - val_loss: 20.9052 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-QXkk3H7k1I",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained ResNet101V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZlM0zjW8Kgw",
        "colab_type": "code",
        "outputId": "622b1aa2-a14b-42c9-d205-1d24c08d46a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'ResNet101V2_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.resnet_v2.ResNet101V2(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('ResNet101V2_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('ResNet101V2_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('ResNet101V2_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('ResNet101V2_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171319296/171317808 [==============================] - 4s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 30.4922 - accuracy: 0.3667 - val_loss: 10.7636 - val_accuracy: 0.4333\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.7027 - accuracy: 0.7667 - val_loss: 9.0807 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.1783 - accuracy: 0.8333 - val_loss: 8.9101 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1593 - accuracy: 0.8833 - val_loss: 13.6244 - val_accuracy: 0.3000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.9667 - val_loss: 12.3554 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7898 - accuracy: 0.9500 - val_loss: 8.8746 - val_accuracy: 0.3667\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.9833 - val_loss: 10.7405 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.9667 - val_loss: 13.1627 - val_accuracy: 0.4333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.9667 - val_loss: 9.0361 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9833 - val_loss: 11.2256 - val_accuracy: 0.3000\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.9833 - val_loss: 9.7942 - val_accuracy: 0.3667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9833 - val_loss: 7.1546 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.5558e-05 - accuracy: 1.0000 - val_loss: 7.4712 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9833 - val_loss: 8.5848 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.1076e-04 - accuracy: 1.0000 - val_loss: 10.8724 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.9667 - val_loss: 9.7985 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.9667 - val_loss: 9.0778 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.9833 - val_loss: 8.8429 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.8879e-04 - accuracy: 1.0000 - val_loss: 10.0524 - val_accuracy: 0.3667\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.7158e-05 - accuracy: 1.0000 - val_loss: 9.7336 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 9.3073 - val_accuracy: 0.4333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 9.2668 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9833 - val_loss: 14.2210 - val_accuracy: 0.3000\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.9727e-04 - accuracy: 1.0000 - val_loss: 11.1440 - val_accuracy: 0.3667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.9833 - val_loss: 9.4937 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9833 - val_loss: 12.0548 - val_accuracy: 0.4333\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3211e-05 - accuracy: 1.0000 - val_loss: 10.2327 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9833 - val_loss: 11.0054 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9833 - val_loss: 11.3670 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9833 - val_loss: 10.0668 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.3459e-12 - accuracy: 1.0000 - val_loss: 10.0668 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9833 - val_loss: 7.6954 - val_accuracy: 0.4333\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.7245e-07 - accuracy: 1.0000 - val_loss: 7.4188 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.8329e-08 - accuracy: 1.0000 - val_loss: 7.9929 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.5975e-12 - accuracy: 1.0000 - val_loss: 7.9929 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.9833 - val_loss: 7.4328 - val_accuracy: 0.3667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.6446e-05 - accuracy: 1.0000 - val_loss: 6.3101 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.7964e-05 - accuracy: 1.0000 - val_loss: 6.8817 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.0408e-06 - accuracy: 1.0000 - val_loss: 6.3895 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.3430e-07 - accuracy: 1.0000 - val_loss: 6.5506 - val_accuracy: 0.3667\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.1357e-09 - accuracy: 1.0000 - val_loss: 6.5452 - val_accuracy: 0.3667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0031e-07 - accuracy: 1.0000 - val_loss: 6.0069 - val_accuracy: 0.3667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.5024e-10 - accuracy: 1.0000 - val_loss: 6.0180 - val_accuracy: 0.3667\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0076e-08 - accuracy: 1.0000 - val_loss: 6.0484 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.8646e-09 - accuracy: 1.0000 - val_loss: 6.0722 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.4659 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.9636e-07 - accuracy: 1.0000 - val_loss: 7.4931 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9902e-04 - accuracy: 1.0000 - val_loss: 9.2199 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 7.4583e-06 - accuracy: 1.0000 - val_loss: 8.9149 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3261e-11 - accuracy: 1.0000 - val_loss: 8.9137 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL1WV04g7ntR",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained ResNet152V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQdh3VrA8RP7",
        "colab_type": "code",
        "outputId": "e88487c1-eb63-4b63-e7e7-a7c7e6d0ff97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'ResNet152V2_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.resnet_v2.ResNet152V2(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('ResNet152V2_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('ResNet152V2_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('ResNet152V2_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('ResNet152V2_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 5s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 22.3311 - accuracy: 0.5167 - val_loss: 13.9392 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.5229 - accuracy: 0.7833 - val_loss: 9.8014 - val_accuracy: 0.4333\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5438 - accuracy: 0.8500 - val_loss: 19.7848 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0229 - accuracy: 0.9167 - val_loss: 18.6276 - val_accuracy: 0.3000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3014 - accuracy: 0.9167 - val_loss: 22.1667 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.9500 - val_loss: 17.4494 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.9667 - val_loss: 20.5540 - val_accuracy: 0.4333\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.9333 - val_loss: 10.9650 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.9504 - accuracy: 0.9500 - val_loss: 14.8564 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0832e-07 - accuracy: 1.0000 - val_loss: 14.8602 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 4.9270e-05 - accuracy: 1.0000 - val_loss: 14.5003 - val_accuracy: 0.3667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9573e-07 - accuracy: 1.0000 - val_loss: 14.5514 - val_accuracy: 0.3667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.7466e-07 - accuracy: 1.0000 - val_loss: 14.3690 - val_accuracy: 0.3667\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7269e-07 - accuracy: 1.0000 - val_loss: 14.3811 - val_accuracy: 0.3667\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.3029e-08 - accuracy: 1.0000 - val_loss: 14.3865 - val_accuracy: 0.3667\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.9831e-10 - accuracy: 1.0000 - val_loss: 14.3865 - val_accuracy: 0.3667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.9667 - val_loss: 12.3595 - val_accuracy: 0.3667\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.8037e-05 - accuracy: 1.0000 - val_loss: 12.8900 - val_accuracy: 0.3667\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.5095e-07 - accuracy: 1.0000 - val_loss: 12.7618 - val_accuracy: 0.3667\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.3750e-07 - accuracy: 1.0000 - val_loss: 12.6735 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4505e-08 - accuracy: 1.0000 - val_loss: 12.6659 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3635e-04 - accuracy: 1.0000 - val_loss: 11.8901 - val_accuracy: 0.3667\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.1376e-08 - accuracy: 1.0000 - val_loss: 11.9057 - val_accuracy: 0.3667\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 5.5525e-04 - accuracy: 1.0000 - val_loss: 12.1876 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9833 - val_loss: 13.7300 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.7298e-05 - accuracy: 1.0000 - val_loss: 14.0418 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 13.7466 - val_accuracy: 0.3667\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 15.9581 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 9.2295e-08 - accuracy: 1.0000 - val_loss: 16.3426 - val_accuracy: 0.3667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9833 - val_loss: 16.1956 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0813e-05 - accuracy: 1.0000 - val_loss: 16.7068 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.5565e-04 - accuracy: 1.0000 - val_loss: 17.1044 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2598e-09 - accuracy: 1.0000 - val_loss: 17.1068 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 8.6581e-04 - accuracy: 1.0000 - val_loss: 16.0923 - val_accuracy: 0.3667\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9833 - val_loss: 17.0998 - val_accuracy: 0.4333\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 15.9999 - val_accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0302e-08 - accuracy: 1.0000 - val_loss: 16.0342 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 6.3830e-05 - accuracy: 1.0000 - val_loss: 18.9832 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 18.9347 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.3279e-11 - accuracy: 1.0000 - val_loss: 18.9347 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 19.2179 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.9364e-07 - accuracy: 1.0000 - val_loss: 20.0875 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.4087e-06 - accuracy: 1.0000 - val_loss: 26.1407 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8697e-05 - accuracy: 1.0000 - val_loss: 23.6978 - val_accuracy: 0.3000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.6270e-05 - accuracy: 1.0000 - val_loss: 25.1490 - val_accuracy: 0.4333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9833 - val_loss: 19.7176 - val_accuracy: 0.3667\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.0624e-09 - accuracy: 1.0000 - val_loss: 19.7419 - val_accuracy: 0.3667\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.6279e-12 - accuracy: 1.0000 - val_loss: 19.7419 - val_accuracy: 0.3667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.8743e-10 - accuracy: 1.0000 - val_loss: 19.7419 - val_accuracy: 0.3667\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 3.5271e-09 - accuracy: 1.0000 - val_loss: 19.8851 - val_accuracy: 0.3667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V75UA9gO7sDN",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En_NtPQR8Zt9",
        "colab_type": "code",
        "outputId": "e785e910-9c92-4999-80a5-9ea79ee5aa52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'InceptionV3_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('InceptionV3_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('InceptionV3_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('InceptionV3_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('InceptionV3_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 27.1500 - accuracy: 0.4500 - val_loss: 18.1111 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 25.1997 - accuracy: 0.4833 - val_loss: 22.4643 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 10.5553 - accuracy: 0.7167 - val_loss: 11.3271 - val_accuracy: 0.6000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 7.6588 - accuracy: 0.7667 - val_loss: 41.4603 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 4.0044 - accuracy: 0.9000 - val_loss: 9.0707 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.1483 - accuracy: 0.8000 - val_loss: 17.6419 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.2705 - accuracy: 0.8833 - val_loss: 23.1384 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5415 - accuracy: 0.9167 - val_loss: 21.5667 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6421 - accuracy: 0.9167 - val_loss: 20.4305 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0141 - accuracy: 0.9000 - val_loss: 8.6659 - val_accuracy: 0.4333\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8615 - accuracy: 0.9500 - val_loss: 8.9086 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.9500 - val_loss: 13.6135 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5635 - accuracy: 0.8333 - val_loss: 15.7888 - val_accuracy: 0.5333\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0392 - accuracy: 0.8833 - val_loss: 8.9272 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.9667 - val_loss: 9.9140 - val_accuracy: 0.4333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9833 - val_loss: 10.4506 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.9500 - val_loss: 8.4312 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9667 - val_loss: 9.9673 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9833 - val_loss: 11.3636 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.9500 - val_loss: 11.7671 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1803 - accuracy: 0.8333 - val_loss: 9.3196 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.9833 - val_loss: 16.1728 - val_accuracy: 0.4333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.9333 - val_loss: 9.9062 - val_accuracy: 0.4333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.9833 - val_loss: 16.3323 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9667 - val_loss: 15.2333 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 4.5720e-04 - accuracy: 1.0000 - val_loss: 11.3986 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.6229e-09 - accuracy: 1.0000 - val_loss: 11.3996 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.3255e-10 - accuracy: 1.0000 - val_loss: 11.3997 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2773e-04 - accuracy: 1.0000 - val_loss: 12.8246 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9833 - val_loss: 10.2132 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3966e-10 - accuracy: 1.0000 - val_loss: 10.2132 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.6920e-06 - accuracy: 1.0000 - val_loss: 10.3723 - val_accuracy: 0.5333\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3644e-11 - accuracy: 1.0000 - val_loss: 10.3723 - val_accuracy: 0.5333\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.9833 - val_loss: 13.7433 - val_accuracy: 0.4333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.0750e-06 - accuracy: 1.0000 - val_loss: 12.5332 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.9667 - val_loss: 13.4207 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9892 - accuracy: 0.9500 - val_loss: 33.0365 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 18.2422 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7364e-08 - accuracy: 1.0000 - val_loss: 18.1679 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.9833 - val_loss: 27.3590 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9833 - val_loss: 11.7279 - val_accuracy: 0.5667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9672e-05 - accuracy: 1.0000 - val_loss: 12.4215 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1444e-04 - accuracy: 1.0000 - val_loss: 12.2980 - val_accuracy: 0.5667\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6246 - accuracy: 0.9500 - val_loss: 14.5827 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.8111e-06 - accuracy: 1.0000 - val_loss: 14.7408 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2948 - accuracy: 0.9667 - val_loss: 14.8288 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4341e-09 - accuracy: 1.0000 - val_loss: 14.8101 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.9667 - val_loss: 14.2091 - val_accuracy: 0.4333\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2868e-08 - accuracy: 1.0000 - val_loss: 14.1994 - val_accuracy: 0.4333\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4378e-09 - accuracy: 1.0000 - val_loss: 14.2009 - val_accuracy: 0.4333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhODxBw7wIz",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained InceptionResNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYGVCBZX8iKo",
        "colab_type": "code",
        "outputId": "6ccce5e9-201a-4953-e7c9-50b62757d002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'InceptionResNetV2_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('InceptionResNetV2_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('InceptionResNetV2_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('InceptionResNetV2_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('InceptionResNetV2_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 5s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 27.3640 - accuracy: 0.5167 - val_loss: 17.3882 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 11.2883 - accuracy: 0.5667 - val_loss: 6.2828 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 7.3338 - accuracy: 0.6500 - val_loss: 5.6880 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.7742 - accuracy: 0.7667 - val_loss: 7.1886 - val_accuracy: 0.5333\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2596 - accuracy: 0.7833 - val_loss: 10.3757 - val_accuracy: 0.5333\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5616 - accuracy: 0.8500 - val_loss: 5.2890 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 5.5916 - accuracy: 0.7167 - val_loss: 5.0423 - val_accuracy: 0.2667\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.5162 - accuracy: 0.9000 - val_loss: 4.1966 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.2060 - accuracy: 0.8333 - val_loss: 7.7337 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3270 - accuracy: 0.8500 - val_loss: 11.5018 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6912 - accuracy: 0.8667 - val_loss: 16.9890 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7620 - accuracy: 0.8333 - val_loss: 6.7496 - val_accuracy: 0.4333\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9299 - accuracy: 0.8833 - val_loss: 12.9317 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0608 - accuracy: 0.8167 - val_loss: 6.8662 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.5949 - accuracy: 0.8333 - val_loss: 8.6734 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2615 - accuracy: 0.8667 - val_loss: 11.0805 - val_accuracy: 0.5333\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4012 - accuracy: 0.8333 - val_loss: 11.7530 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0985 - accuracy: 0.9333 - val_loss: 6.4356 - val_accuracy: 0.4333\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2898 - accuracy: 0.8833 - val_loss: 6.2862 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2435 - accuracy: 0.8833 - val_loss: 10.0694 - val_accuracy: 0.4333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1746 - accuracy: 0.8833 - val_loss: 7.4058 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.9000 - val_loss: 6.9824 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.9500 - val_loss: 7.9069 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9667 - val_loss: 9.4983 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.9667 - val_loss: 13.8396 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4583 - accuracy: 0.9000 - val_loss: 11.5166 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.9167 - val_loss: 15.3421 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.9167 - val_loss: 8.8557 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9667 - val_loss: 8.4905 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.9944 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.9667 - val_loss: 10.3300 - val_accuracy: 0.4333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9833 - val_loss: 8.0318 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8365 - accuracy: 0.9167 - val_loss: 6.9842 - val_accuracy: 0.4333\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.9500 - val_loss: 8.9628 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9667 - val_loss: 8.1898 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9833 - val_loss: 8.7780 - val_accuracy: 0.3667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9833 - val_loss: 11.2687 - val_accuracy: 0.3667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.9333 - val_loss: 8.1181 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9833 - val_loss: 8.8220 - val_accuracy: 0.4333\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 9.1894 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.9667 - val_loss: 12.0752 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9500 - val_loss: 11.9010 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9500 - val_loss: 18.1616 - val_accuracy: 0.5333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0101 - accuracy: 0.9000 - val_loss: 12.8507 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9833 - val_loss: 12.0810 - val_accuracy: 0.4333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9833 - val_loss: 11.1011 - val_accuracy: 0.4333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.5905e-04 - accuracy: 1.0000 - val_loss: 10.8810 - val_accuracy: 0.4333\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9833 - val_loss: 9.3888 - val_accuracy: 0.3667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.8368e-04 - accuracy: 1.0000 - val_loss: 9.5344 - val_accuracy: 0.4333\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 10.1595 - val_accuracy: 0.4333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuSe82fy7zlF",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfsXOEdY8rjc",
        "colab_type": "code",
        "outputId": "dcc0f299-35a5-4392-dfa8-7fb63130f8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'MobileNet_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.mobilenet.MobileNet(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('MobileNet_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('MobileNet_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('MobileNet_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('MobileNet_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 1s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 22.0346 - accuracy: 0.4667 - val_loss: 4.1174 - val_accuracy: 0.5333\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.6127 - accuracy: 0.7167 - val_loss: 5.4578 - val_accuracy: 0.3667\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9868 - accuracy: 0.8500 - val_loss: 12.0019 - val_accuracy: 0.5333\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.4809 - accuracy: 0.9000 - val_loss: 6.6601 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.9151 - accuracy: 0.8500 - val_loss: 6.7543 - val_accuracy: 0.4333\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9500 - val_loss: 7.6078 - val_accuracy: 0.4333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9833 - val_loss: 6.2136 - val_accuracy: 0.3667\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.9667 - val_loss: 9.9848 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9833 - val_loss: 8.9544 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.9500 - val_loss: 8.0200 - val_accuracy: 0.4333\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.9500 - val_loss: 9.4651 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9667 - val_loss: 8.7515 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.9667 - val_loss: 6.8157 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9833 - val_loss: 11.8133 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9667 - val_loss: 6.4237 - val_accuracy: 0.4333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 8.9921 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9833 - val_loss: 8.1381 - val_accuracy: 0.3667\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9667 - val_loss: 7.2516 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9667 - val_loss: 7.0029 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 4.3969e-09 - accuracy: 1.0000 - val_loss: 7.0003 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 7.3299 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1037e-06 - accuracy: 1.0000 - val_loss: 7.3296 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0995e-09 - accuracy: 1.0000 - val_loss: 7.3265 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 8.9070e-08 - accuracy: 1.0000 - val_loss: 7.3854 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.8518e-10 - accuracy: 1.0000 - val_loss: 7.3853 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.9667 - val_loss: 8.9985 - val_accuracy: 0.4333\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9833 - val_loss: 7.2110 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9833 - val_loss: 8.8770 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3249e-06 - accuracy: 1.0000 - val_loss: 8.4955 - val_accuracy: 0.4333\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.4141e-08 - accuracy: 1.0000 - val_loss: 8.4580 - val_accuracy: 0.4333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5746e-08 - accuracy: 1.0000 - val_loss: 8.5243 - val_accuracy: 0.4333\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2734e-07 - accuracy: 1.0000 - val_loss: 8.4167 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.9786e-07 - accuracy: 1.0000 - val_loss: 8.6948 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9833 - val_loss: 8.3753 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.6025e-06 - accuracy: 1.0000 - val_loss: 9.1503 - val_accuracy: 0.4333\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0910e-08 - accuracy: 1.0000 - val_loss: 8.9909 - val_accuracy: 0.4333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7156e-07 - accuracy: 1.0000 - val_loss: 9.7881 - val_accuracy: 0.4333\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 5.5252e-10 - accuracy: 1.0000 - val_loss: 9.7881 - val_accuracy: 0.4333\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9833 - val_loss: 8.6654 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0591e-07 - accuracy: 1.0000 - val_loss: 8.3529 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3638e-09 - accuracy: 1.0000 - val_loss: 8.3674 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9833 - val_loss: 9.2374 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 6.8222e-05 - accuracy: 1.0000 - val_loss: 12.9547 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.5950e-06 - accuracy: 1.0000 - val_loss: 11.4299 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4434e-05 - accuracy: 1.0000 - val_loss: 8.6781 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9833 - val_loss: 11.8868 - val_accuracy: 0.4333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0551e-10 - accuracy: 1.0000 - val_loss: 11.8806 - val_accuracy: 0.4333\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 7.6423e-07 - accuracy: 1.0000 - val_loss: 10.8144 - val_accuracy: 0.4333\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.2919e-13 - accuracy: 1.0000 - val_loss: 10.8144 - val_accuracy: 0.4333\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.6406e-09 - accuracy: 1.0000 - val_loss: 10.6236 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjvBlFvA75Km",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxkCgMjh80hn",
        "colab_type": "code",
        "outputId": "8b1bd663-3df4-44ae-92c3-b6ff982c3785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'DenseNet121_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.densenet.DenseNet121(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('DenseNet121_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('DenseNet121_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('DenseNet121_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('DenseNet121_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 14.0732 - accuracy: 0.5333 - val_loss: 26.1559 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 6.2392 - accuracy: 0.6833 - val_loss: 18.8357 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 4.6687 - accuracy: 0.6667 - val_loss: 7.5830 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.8811 - accuracy: 0.8167 - val_loss: 4.7827 - val_accuracy: 0.5667\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.7465 - accuracy: 0.8333 - val_loss: 4.2265 - val_accuracy: 0.4667\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.9167 - val_loss: 14.2972 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.2918 - accuracy: 0.8500 - val_loss: 7.9841 - val_accuracy: 0.3667\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9490 - accuracy: 0.9000 - val_loss: 8.5066 - val_accuracy: 0.4333\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1676 - accuracy: 0.9167 - val_loss: 6.5732 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.9167 - val_loss: 5.8250 - val_accuracy: 0.4333\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9833 - val_loss: 5.7964 - val_accuracy: 0.3667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.9500 - val_loss: 4.8644 - val_accuracy: 0.4333\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9667 - val_loss: 5.6028 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.3393e-04 - accuracy: 1.0000 - val_loss: 5.5423 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0441 - accuracy: 0.8667 - val_loss: 5.8176 - val_accuracy: 0.3667\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.9333 - val_loss: 8.9366 - val_accuracy: 0.3667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.9500 - val_loss: 7.7591 - val_accuracy: 0.4333\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9833 - val_loss: 7.4052 - val_accuracy: 0.2667\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.3358 - val_accuracy: 0.4333\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9667 - val_loss: 6.8597 - val_accuracy: 0.3000\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.9667 - val_loss: 6.4953 - val_accuracy: 0.4333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9667 - val_loss: 8.0985 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9667 - val_loss: 10.1061 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9833 - val_loss: 12.9547 - val_accuracy: 0.3667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.9667 - val_loss: 7.1807 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9833 - val_loss: 11.7820 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9333 - val_loss: 8.0672 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.0451e-04 - accuracy: 1.0000 - val_loss: 10.5339 - val_accuracy: 0.5333\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.9500 - val_loss: 9.7460 - val_accuracy: 0.3667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.0893e-05 - accuracy: 1.0000 - val_loss: 9.9382 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.9023e-04 - accuracy: 1.0000 - val_loss: 9.5542 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 1.1966e-06 - accuracy: 1.0000 - val_loss: 9.4922 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.9333 - val_loss: 10.0777 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0178e-06 - accuracy: 1.0000 - val_loss: 10.1066 - val_accuracy: 0.4333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.1852e-09 - accuracy: 1.0000 - val_loss: 10.1071 - val_accuracy: 0.4333\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9500 - val_loss: 9.7323 - val_accuracy: 0.4333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 5.1872e-07 - accuracy: 1.0000 - val_loss: 9.7702 - val_accuracy: 0.4333\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9833 - val_loss: 10.2965 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.9500 - val_loss: 17.1345 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 5.0793e-04 - accuracy: 1.0000 - val_loss: 11.8236 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.8514 - accuracy: 0.9333 - val_loss: 14.4991 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9833 - val_loss: 16.8140 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.2261e-04 - accuracy: 1.0000 - val_loss: 13.7359 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 3.4757e-05 - accuracy: 1.0000 - val_loss: 13.4091 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.1973e-06 - accuracy: 1.0000 - val_loss: 13.3960 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 2.0629e-05 - accuracy: 1.0000 - val_loss: 13.7399 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 7.1426e-08 - accuracy: 1.0000 - val_loss: 13.7434 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 4.2759e-08 - accuracy: 1.0000 - val_loss: 13.7591 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 9.9466e-08 - accuracy: 1.0000 - val_loss: 13.7770 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9833 - val_loss: 14.9946 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x9C2RTZ9Ksh",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained DenseNet169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDgRLDIS9ObA",
        "colab_type": "code",
        "outputId": "232fb2d6-2599-4b23-f019-c36a090b1ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'DenseNet169_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.densenet.DenseNet169(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('DenseNet169_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('DenseNet169_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('DenseNet169_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('DenseNet169_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 1s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 31.1693 - accuracy: 0.4500 - val_loss: 13.9196 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 16.5808 - accuracy: 0.5167 - val_loss: 13.0544 - val_accuracy: 0.4667\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.8742 - accuracy: 0.7167 - val_loss: 6.7656 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1778 - accuracy: 0.8167 - val_loss: 10.3795 - val_accuracy: 0.3667\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.3147 - accuracy: 0.6833 - val_loss: 15.8024 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.5178 - accuracy: 0.7667 - val_loss: 9.2851 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4752 - accuracy: 0.8500 - val_loss: 14.6614 - val_accuracy: 0.4333\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9833 - accuracy: 0.8500 - val_loss: 12.0954 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9667 - val_loss: 12.2989 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3741 - accuracy: 0.8833 - val_loss: 10.8502 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0205 - accuracy: 0.9333 - val_loss: 15.2022 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.9500 - val_loss: 8.4176 - val_accuracy: 0.3667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.3752 - accuracy: 0.8667 - val_loss: 8.4936 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1778e-04 - accuracy: 1.0000 - val_loss: 8.5338 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9833 - val_loss: 20.1544 - val_accuracy: 0.4333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6254 - accuracy: 0.8000 - val_loss: 8.7589 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0021 - accuracy: 0.9000 - val_loss: 8.6274 - val_accuracy: 0.4333\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.9500 - val_loss: 9.2961 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.9500 - val_loss: 16.9742 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.9000 - val_loss: 11.8335 - val_accuracy: 0.4333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9833 - val_loss: 13.2776 - val_accuracy: 0.4333\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9833 - val_loss: 8.7571 - val_accuracy: 0.4667\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9833 - val_loss: 14.5562 - val_accuracy: 0.4333\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7431 - accuracy: 0.9333 - val_loss: 11.2111 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9833 - val_loss: 12.0251 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0116e-09 - accuracy: 1.0000 - val_loss: 12.0250 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3255e-05 - accuracy: 1.0000 - val_loss: 12.0207 - val_accuracy: 0.4667\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.9167 - val_loss: 14.6249 - val_accuracy: 0.4333\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9500 - val_loss: 12.9678 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8794e-05 - accuracy: 1.0000 - val_loss: 13.1875 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3827e-06 - accuracy: 1.0000 - val_loss: 13.2133 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8758e-06 - accuracy: 1.0000 - val_loss: 13.4026 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.6705e-04 - accuracy: 1.0000 - val_loss: 12.8801 - val_accuracy: 0.4333\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9833 - val_loss: 19.9930 - val_accuracy: 0.4333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 12.7973 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.9333 - val_loss: 14.9250 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9833 - val_loss: 14.9282 - val_accuracy: 0.4333\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.9333 - val_loss: 15.6323 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2933e-04 - accuracy: 1.0000 - val_loss: 16.2801 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.4558e-05 - accuracy: 1.0000 - val_loss: 15.1270 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.9667 - val_loss: 14.3813 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.9667 - val_loss: 15.2597 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9833 - val_loss: 16.9994 - val_accuracy: 0.4333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.9606e-06 - accuracy: 1.0000 - val_loss: 16.5585 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7997 - accuracy: 0.9667 - val_loss: 16.9166 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.9833 - val_loss: 19.2852 - val_accuracy: 0.4333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 14.9487 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.9667 - val_loss: 16.5266 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.8178e-06 - accuracy: 1.0000 - val_loss: 16.6184 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.9667 - val_loss: 16.7781 - val_accuracy: 0.4333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cTu1yRX9WHt",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGC8wfMD9Ysw",
        "colab_type": "code",
        "outputId": "2cba2043-8791-413b-88fc-9e9dac0efa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'DenseNet201_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.densenet.DenseNet201(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('DenseNet201_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('DenseNet201_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('DenseNet201_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('DenseNet201_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 2s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 22.4886 - accuracy: 0.4333 - val_loss: 15.1740 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.5998 - accuracy: 0.6500 - val_loss: 5.8308 - val_accuracy: 0.3667\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.3003 - accuracy: 0.7167 - val_loss: 5.8871 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.4077 - accuracy: 0.8000 - val_loss: 6.4184 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2795 - accuracy: 0.8833 - val_loss: 7.2053 - val_accuracy: 0.4333\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5495 - accuracy: 0.7500 - val_loss: 9.3716 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.7409 - accuracy: 0.8333 - val_loss: 11.0401 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.9633 - accuracy: 0.8000 - val_loss: 7.2099 - val_accuracy: 0.3667\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4750 - accuracy: 0.9000 - val_loss: 9.1693 - val_accuracy: 0.4333\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.9333 - val_loss: 11.2193 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.9500 - val_loss: 10.0773 - val_accuracy: 0.5333\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9833 - val_loss: 13.0745 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.9500 - val_loss: 19.1046 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3855 - accuracy: 0.8833 - val_loss: 10.3869 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.9667 - val_loss: 9.6205 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1529 - accuracy: 0.9167 - val_loss: 10.9718 - val_accuracy: 0.4333\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.7237e-04 - accuracy: 1.0000 - val_loss: 10.8297 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.9500 - val_loss: 12.6443 - val_accuracy: 0.4333\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9833 - val_loss: 12.5026 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.2441e-04 - accuracy: 1.0000 - val_loss: 11.1970 - val_accuracy: 0.3000\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9667 - val_loss: 10.4733 - val_accuracy: 0.2667\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8348 - accuracy: 0.9500 - val_loss: 13.4014 - val_accuracy: 0.3667\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.9500 - val_loss: 12.0057 - val_accuracy: 0.2667\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0239 - accuracy: 0.8667 - val_loss: 15.6378 - val_accuracy: 0.4333\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9667 - val_loss: 16.5724 - val_accuracy: 0.4333\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 18.1540 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.9667 - val_loss: 11.9387 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.9167 - val_loss: 18.4716 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.9833 - val_loss: 12.7032 - val_accuracy: 0.3000\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.9500 - val_loss: 13.3875 - val_accuracy: 0.3000\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.5392e-04 - accuracy: 1.0000 - val_loss: 12.9501 - val_accuracy: 0.3667\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 14.8625 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1832e-05 - accuracy: 1.0000 - val_loss: 14.4129 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3026e-06 - accuracy: 1.0000 - val_loss: 14.4410 - val_accuracy: 0.4333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9833 - val_loss: 14.2743 - val_accuracy: 0.2667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.9833 - val_loss: 17.9310 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.9500 - val_loss: 15.4294 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 13.2448 - val_accuracy: 0.3000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9833 - val_loss: 16.8567 - val_accuracy: 0.3667\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9833 - val_loss: 15.7292 - val_accuracy: 0.3667\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.9500 - val_loss: 15.1286 - val_accuracy: 0.3000\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.9500 - val_loss: 14.8659 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0624e-05 - accuracy: 1.0000 - val_loss: 14.5057 - val_accuracy: 0.3000\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9667 - val_loss: 18.0032 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.1665e-07 - accuracy: 1.0000 - val_loss: 17.9602 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3994e-05 - accuracy: 1.0000 - val_loss: 16.5772 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.2548e-04 - accuracy: 1.0000 - val_loss: 14.2983 - val_accuracy: 0.3667\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9833 - val_loss: 20.4023 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.5260e-08 - accuracy: 1.0000 - val_loss: 20.3831 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 17.3794 - val_accuracy: 0.3667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rnCxqUr77TU",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained NASNetLarge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bo6XteD9i28",
        "colab_type": "code",
        "outputId": "c3e43623-bb33-4113-c48a-c3047d8c79b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 331, 331\n",
        "\n",
        "top_model_weights_path = 'NASNetLarge_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.nasnet.NASNetLarge(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('NASNetLarge_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('NASNetLarge_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('NASNetLarge_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('NASNetLarge_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5\n",
            "343613440/343610240 [==============================] - 9s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 73.4059 - accuracy: 0.4833 - val_loss: 17.7338 - val_accuracy: 0.4333\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 15.1476 - accuracy: 0.7667 - val_loss: 24.9637 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 5.2403 - accuracy: 0.9167 - val_loss: 22.7336 - val_accuracy: 0.3667\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.5567 - accuracy: 0.8500 - val_loss: 24.7745 - val_accuracy: 0.4333\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.6494 - accuracy: 0.9333 - val_loss: 25.5122 - val_accuracy: 0.4333\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.4874 - accuracy: 0.9667 - val_loss: 15.3573 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.5746 - accuracy: 0.9667 - val_loss: 18.0209 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.8724e-10 - accuracy: 1.0000 - val_loss: 18.0206 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.5642e-14 - accuracy: 1.0000 - val_loss: 18.0206 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.5099 - accuracy: 0.9833 - val_loss: 24.6974 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.6251 - accuracy: 0.9500 - val_loss: 16.3906 - val_accuracy: 0.5667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 4.1479e-13 - accuracy: 1.0000 - val_loss: 16.3906 - val_accuracy: 0.5667\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.3265 - accuracy: 0.9500 - val_loss: 16.9773 - val_accuracy: 0.5333\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.3434e-05 - accuracy: 1.0000 - val_loss: 18.4822 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.5620 - accuracy: 0.9500 - val_loss: 26.5205 - val_accuracy: 0.4333\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.4238 - accuracy: 0.9667 - val_loss: 26.1431 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.3949e-09 - accuracy: 1.0000 - val_loss: 26.1405 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 4.9126e-07 - accuracy: 1.0000 - val_loss: 26.0400 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.8606 - accuracy: 0.9667 - val_loss: 19.4025 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.2283e-09 - accuracy: 1.0000 - val_loss: 19.3956 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.0395 - accuracy: 0.9833 - val_loss: 17.8673 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 4.2454e-14 - accuracy: 1.0000 - val_loss: 17.8673 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.1617 - accuracy: 0.9833 - val_loss: 22.8980 - val_accuracy: 0.3667\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 5.1889e-05 - accuracy: 1.0000 - val_loss: 23.1766 - val_accuracy: 0.3667\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.5375e-10 - accuracy: 1.0000 - val_loss: 23.1766 - val_accuracy: 0.3667\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.8368e-21 - accuracy: 1.0000 - val_loss: 23.1766 - val_accuracy: 0.3667\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.5845e-13 - accuracy: 1.0000 - val_loss: 23.1766 - val_accuracy: 0.3667\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 4.4896e-05 - accuracy: 1.0000 - val_loss: 23.8388 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.0016e-08 - accuracy: 1.0000 - val_loss: 23.9992 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.5502 - accuracy: 0.9500 - val_loss: 31.8604 - val_accuracy: 0.3667\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.1144e-17 - accuracy: 1.0000 - val_loss: 31.8604 - val_accuracy: 0.3667\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.5262 - accuracy: 0.9833 - val_loss: 38.5900 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.2015 - accuracy: 0.9833 - val_loss: 31.2299 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.5811e-18 - accuracy: 1.0000 - val_loss: 31.2299 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.6203 - accuracy: 0.9167 - val_loss: 33.3577 - val_accuracy: 0.4333\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.8425 - accuracy: 0.9667 - val_loss: 23.1152 - val_accuracy: 0.4333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.8854 - accuracy: 0.9667 - val_loss: 41.6486 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 3.4955e-05 - accuracy: 1.0000 - val_loss: 38.7891 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.7346 - accuracy: 0.9833 - val_loss: 22.8351 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 1.6289e-22 - accuracy: 1.0000 - val_loss: 22.8351 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.3951e-08 - accuracy: 1.0000 - val_loss: 22.3890 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.3946e-19 - accuracy: 1.0000 - val_loss: 22.3890 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.4321e-18 - accuracy: 1.0000 - val_loss: 22.3890 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.9918 - accuracy: 0.9667 - val_loss: 23.9764 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.5537 - accuracy: 0.9667 - val_loss: 33.0479 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.6055e-19 - accuracy: 1.0000 - val_loss: 33.0479 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 7.8338e-15 - accuracy: 1.0000 - val_loss: 33.0479 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.2118 - accuracy: 0.9833 - val_loss: 19.4881 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.0382 - accuracy: 0.9833 - val_loss: 21.7143 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.8042e-04 - accuracy: 1.0000 - val_loss: 19.1204 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyRI71c69rw9",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained NASNETMobile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0EgH7469uiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'NASNetMobile_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.nasnet.NASNetMobile(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('NASNetMobile_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('NASNetMobile_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('NASNetMobile_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('NASNetMobile_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow0fs_-x79T-",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDiXSVg9915q",
        "colab_type": "code",
        "outputId": "7b51cadb-0cdb-4e84-8a2c-79f57f3c637f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = 'MobileNetV2_bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "nb_train_samples = 60\n",
        "nb_validation_samples = 30\n",
        "epochs = 50\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples // batch_size)\n",
        "    np.save(open('MobileNetV2_bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples // batch_size)\n",
        "    np.save(open('MobileNetV2_bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('MobileNetV2_bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "    validation_data = np.load(open('MobileNetV2_bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(validation_data, validation_labels))\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n",
            "Found 119 images belonging to 2 classes.\n",
            "Found 69 images belonging to 2 classes.\n",
            "Train on 60 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 27.9950 - accuracy: 0.4500 - val_loss: 17.5767 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 11.1801 - accuracy: 0.6667 - val_loss: 6.5539 - val_accuracy: 0.4667\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.2443 - accuracy: 0.7333 - val_loss: 17.0468 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4602 - accuracy: 0.8500 - val_loss: 6.3833 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.9333 - val_loss: 11.9861 - val_accuracy: 0.5333\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.8910 - accuracy: 0.8833 - val_loss: 10.7540 - val_accuracy: 0.3667\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1095 - accuracy: 0.9167 - val_loss: 10.7949 - val_accuracy: 0.4333\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9372 - accuracy: 0.9167 - val_loss: 12.5962 - val_accuracy: 0.3000\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9667 - val_loss: 10.3662 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 10.0063 - val_accuracy: 0.3000\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9667 - val_loss: 10.3042 - val_accuracy: 0.3667\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.9667 - val_loss: 16.2138 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.9333 - val_loss: 9.6656 - val_accuracy: 0.3000\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.9500 - val_loss: 12.1693 - val_accuracy: 0.4333\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7380 - accuracy: 0.8833 - val_loss: 13.1074 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 9.8216e-04 - accuracy: 1.0000 - val_loss: 15.1137 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9833 - val_loss: 9.1719 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9333 - val_loss: 21.0178 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9398 - accuracy: 0.9500 - val_loss: 15.7451 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9500 - val_loss: 15.3087 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9667 - val_loss: 13.5895 - val_accuracy: 0.3000\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0780e-07 - accuracy: 1.0000 - val_loss: 13.5878 - val_accuracy: 0.3000\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3328e-07 - accuracy: 1.0000 - val_loss: 13.5996 - val_accuracy: 0.3000\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.4033e-10 - accuracy: 1.0000 - val_loss: 13.5996 - val_accuracy: 0.3000\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.8847e-07 - accuracy: 1.0000 - val_loss: 13.5884 - val_accuracy: 0.3000\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.2802e-06 - accuracy: 1.0000 - val_loss: 13.6985 - val_accuracy: 0.3000\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.0521e-05 - accuracy: 1.0000 - val_loss: 14.7688 - val_accuracy: 0.2667\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.0058e-06 - accuracy: 1.0000 - val_loss: 14.4318 - val_accuracy: 0.2667\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.4034e-06 - accuracy: 1.0000 - val_loss: 14.0961 - val_accuracy: 0.2667\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 7.9783e-09 - accuracy: 1.0000 - val_loss: 14.1188 - val_accuracy: 0.2667\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 8.0923e-10 - accuracy: 1.0000 - val_loss: 14.1183 - val_accuracy: 0.2667\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9833 - val_loss: 14.4764 - val_accuracy: 0.3000\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.0395e-09 - accuracy: 1.0000 - val_loss: 14.4718 - val_accuracy: 0.3000\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9833 - val_loss: 16.8215 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1725e-05 - accuracy: 1.0000 - val_loss: 17.3254 - val_accuracy: 0.3667\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9667 - val_loss: 16.2878 - val_accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9833 - val_loss: 14.7362 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.6765e-04 - accuracy: 1.0000 - val_loss: 11.7596 - val_accuracy: 0.3000\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9667 - val_loss: 11.5897 - val_accuracy: 0.3000\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.1976e-12 - accuracy: 1.0000 - val_loss: 11.5897 - val_accuracy: 0.3000\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.3435e-06 - accuracy: 1.0000 - val_loss: 12.5158 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.3484e-04 - accuracy: 1.0000 - val_loss: 12.3928 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 5.7643e-07 - accuracy: 1.0000 - val_loss: 12.0648 - val_accuracy: 0.2333\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 1.1199e-10 - accuracy: 1.0000 - val_loss: 12.0646 - val_accuracy: 0.2333\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 4.8601e-13 - accuracy: 1.0000 - val_loss: 12.0646 - val_accuracy: 0.2333\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 3.7477e-05 - accuracy: 1.0000 - val_loss: 16.6766 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.5188e-05 - accuracy: 1.0000 - val_loss: 15.6928 - val_accuracy: 0.3667\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 16.2044 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 2.4511e-11 - accuracy: 1.0000 - val_loss: 16.2044 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 6.0176e-08 - accuracy: 1.0000 - val_loss: 15.8987 - val_accuracy: 0.3667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Bkhao29-5K",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    }
  ]
}